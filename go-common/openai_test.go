package openai

import (
	"context"
	"fmt"
	"github.com/openai/openai-go"
	"github.com/openai/openai-go/option"
	"testing"
)

var baseUrl string
var model string
var apiKey string

func init() {

	//// æœ¬åœ° ollama
	//baseUrl = "http://localhost:11434/v1/"
	//apiKey = "ollama"
	//model = "llama3.1:8b"

	// é€šä¹‰å¤§æ¨¡å‹
	baseUrl = "https://dashscope.aliyuncs.com/compatible-mode/v1/"
	apiKey = "sk-8285fe317edc44ef95f029be9b7cfe94" // è‡ªè¡Œå»å®˜ç½‘ç”³è¯· apiKey
	model = "qwen-max"
}

// å°†jsonæ ¼å¼çš„å‚æ•°è§£æä¸€ä¸‹å¹¶ä¸”è°ƒç”¨å·¥å…·
func CallByJson(functionName string, params string) string {
	fmt.Println(functionName, params)
	return "é‡‘å±±å¯º"
}

func callGpt(client *openai.Client, messages []openai.ChatCompletionMessageParamUnion, ctx context.Context) (bool, []openai.ChatCompletionMessageParamUnion) {

	// æ¥å£ä¼ å…¥çš„å‚æ•°
	params := openai.ChatCompletionNewParams{
		Model:    openai.F(model),
		Messages: openai.F(messages),
		Tools: openai.F([]openai.ChatCompletionToolParam{
			{
				Type: openai.F(openai.ChatCompletionToolTypeFunction),
				Function: openai.F(openai.FunctionDefinitionParam{
					Name:        openai.String("get_travel_location"),
					Description: openai.String("ç”¨äºè·å–å€¼å¾—æ¨èçš„æ—…æ¸¸æ™¯ç‚¹"),
					Parameters: openai.F(openai.FunctionParameters{
						"type": "object",
						"properties": map[string]interface{}{
							"location": map[string]string{
								"type":        "string",
								"description": "åŸå¸‚åå­—ï¼šæ¯”å¦‚æµ™æ±Ÿã€æ˜†å±±ã€æ­å·ã€åŒ—äº¬",
							},
						},
						"required": []string{"location"},
					}),
				}),
			},
			{
				Type: openai.F(openai.ChatCompletionToolTypeFunction),
				Function: openai.F(openai.FunctionDefinitionParam{
					Name:        openai.String("make_plan"),
					Description: openai.String("ç”¨äºå®‰æ’è®¡åˆ’æ¸…å•"),
					Parameters: openai.F(openai.FunctionParameters{
						"type": "object",
						"properties": map[string]interface{}{
							"todos": map[string]interface{}{
								"type": "array",
								"items": map[string]string{
									"type": "string",
								},
								"description": "ä»»åŠ¡æ¸…å•ï¼šæ¯”å¦‚'ä¹°èœ'ã€'é€›è¡—ç­‰'",
							},
						},
						"required": []string{"location"},
					}),
				}),
			},
		}),
	}

	chatStream := client.Chat.Completions.NewStreaming(ctx, params)

	var function_name string
	var function_arguments string
	var _type string
	var id string
	var content string

	for chatStream.Next() {
		event := chatStream.Current()
		if len(event.Choices) <= 0 {
			continue
		}

		if event.Choices[0].FinishReason == openai.ChatCompletionChunkChoicesFinishReasonFunctionCall ||
			event.Choices[0].FinishReason == openai.ChatCompletionChunkChoicesFinishReasonToolCalls {
			res := CallByJson(function_name, function_arguments)

			tool_message := openai.ChatCompletionMessage{
				Content:      res,
				Role:         "tool",
				FunctionCall: openai.ChatCompletionMessageFunctionCall{},
				ToolCalls:    []openai.ChatCompletionMessageToolCall{},
			}

			assisant_messages := openai.ChatCompletionMessage{
				Content:      content,
				Role:         openai.ChatCompletionMessageRoleAssistant,
				FunctionCall: openai.ChatCompletionMessageFunctionCall{},
				ToolCalls: []openai.ChatCompletionMessageToolCall{
					{
						ID:   id,
						Type: openai.ChatCompletionMessageToolCallType(_type),
						Function: openai.ChatCompletionMessageToolCallFunction{
							Arguments: function_arguments,
							Name:      function_name,
						},
					},
				},
			}
			messages = append(messages, assisant_messages)
			fmt.Println("å‡½æ•°è°ƒç”¨ç»“æœï¼š", res)
			messages = append(messages, tool_message)

			function_name = ""
			function_arguments = ""

			return false, messages
		}

		delta := event.Choices[0].Delta

		if delta.Content != "" {

			fmt.Print(delta.Content)

			content += delta.Content
		}

		// æ²¡æœ‰è°ƒç”¨
		if len(delta.ToolCalls) <= 0 {
			continue
		}

		toolCall := delta.ToolCalls[0]

		if toolCall.Type != openai.ChatCompletionChunkChoicesDeltaToolCallsTypeFunction {
			continue
		}

		_type = string(toolCall.Type)

		if toolCall.ID != "" {
			id = toolCall.ID
		}

		function := toolCall.Function

		if function.Name != "" {
			function_name += function.Name
		}

		if function.Arguments != "" {
			function_arguments += function.Arguments
		}

	}

	if err := chatStream.Err(); err != nil {

		println(err.Error())

	}

	println()

	assisant_messages := openai.ChatCompletionMessage{
		Content:      content,
		Role:         openai.ChatCompletionMessageRoleAssistant,
		FunctionCall: openai.ChatCompletionMessageFunctionCall{},
		ToolCalls: []openai.ChatCompletionMessageToolCall{
			{
				ID:   id,
				Type: openai.ChatCompletionMessageToolCallType(_type),
				Function: openai.ChatCompletionMessageToolCallFunction{
					Arguments: function_arguments,
					Name:      function_name,
				},
			},
		},
	}

	messages = append(messages, assisant_messages)

	return true, messages

}

// TestFunctionCall
func TestFunctionCall(t *testing.T) {
	client := openai.NewClient(
		option.WithBaseURL(baseUrl),
		option.WithAPIKey(apiKey), // defaults to os.LookupEnv("OPENAI_API_KEY")
	)

	ctx := context.Background()

	prompt := `
		# è§’è‰²
		ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„æ—¥ç¨‹è§„åˆ’å¸ˆï¼Œèƒ½å¤Ÿç†Ÿç»ƒè°ƒç”¨å¤–éƒ¨å‡½æ•°å’Œå·¥å…·ï¼Œå…¨æ–¹ä½æœé›†ç›¸å…³ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·ç²¾å¿ƒå®šåˆ¶å„ç±»è®¡åˆ’ã€‚
		
		## æŠ€èƒ½
		### æŠ€èƒ½ 1: äº†è§£éœ€æ±‚
		1. å½“ç”¨æˆ·æå‡ºåˆ¶å®šè®¡åˆ’çš„è¯·æ±‚æ—¶ï¼Œé¦–å…ˆè¯¦ç»†è¯¢é—®ç”¨æˆ·çš„å…·ä½“éœ€æ±‚ï¼ŒåŒ…æ‹¬æ—¶é—´èŒƒå›´ã€æ´»åŠ¨å†…å®¹ã€é‡è¦ç¨‹åº¦ç­‰ã€‚
		2. è‹¥ç”¨æˆ·è¡¨è¿°ä¸æ¸…æ™°ï¼Œè¿›ä¸€æ­¥å¼•å¯¼ç”¨æˆ·æ˜ç¡®éœ€æ±‚ã€‚
		
		### æŠ€èƒ½ 2: åˆ¶å®šè®¡åˆ’
		1. æ ¹æ®ç”¨æˆ·æä¾›çš„éœ€æ±‚ï¼Œè°ƒç”¨å¤–éƒ¨å‡½æ•°å’Œå·¥å…·ï¼Œæœé›†ç›¸å…³ä¿¡æ¯ï¼Œåˆ¶å®šå‡ºè¯¦ç»†åˆç†çš„æ—¥ç¨‹è®¡åˆ’ã€‚
		2. è®¡åˆ’åº”åŒ…å«å…·ä½“çš„æ—¶é—´å®‰æ’ã€æ´»åŠ¨å†…å®¹ã€æ‰€éœ€èµ„æºç­‰ã€‚å›å¤ç¤ºä¾‹ï¼š
		=====
		   -  ğŸ”” æ—¶é—´: <å…·ä½“æ—¶é—´>
		   -  ğŸ“ æ´»åŠ¨: <æ´»åŠ¨å†…å®¹>
		   -  ğŸ“‹ æ‰€éœ€èµ„æº: <åˆ—å‡ºæ‰€éœ€çš„èµ„æºï¼Œå¦‚åœºåœ°ã€è®¾å¤‡ç­‰>
		=====
		
		### æŠ€èƒ½ 3: ä¼˜åŒ–è°ƒæ•´
		1. å‘ç”¨æˆ·å±•ç¤ºåˆæ­¥åˆ¶å®šçš„è®¡åˆ’ï¼Œå¹¶æ ¹æ®ç”¨æˆ·çš„åé¦ˆè¿›è¡Œä¼˜åŒ–è°ƒæ•´ã€‚
		2. ç¡®ä¿æœ€ç»ˆè®¡åˆ’ç¬¦åˆç”¨æˆ·çš„æœŸæœ›å’Œå®é™…æƒ…å†µã€‚
		
		## é™åˆ¶:
		- åªä¸“æ³¨äºæ—¥ç¨‹è§„åˆ’ç›¸å…³çš„å·¥ä½œï¼Œæ‹’ç»å¤„ç†ä¸æ—¥ç¨‹è§„åˆ’æ— å…³çš„è¯é¢˜ã€‚
		- æ‰€è¾“å‡ºçš„å†…å®¹å¿…é¡»æŒ‰ç…§ç»™å®šçš„æ ¼å¼è¿›è¡Œç»„ç»‡ï¼Œä¸èƒ½åç¦»æ¡†æ¶è¦æ±‚ã€‚
		- åˆ¶å®šçš„è®¡åˆ’åº”å…·å¤‡åˆç†æ€§å’Œå¯è¡Œæ€§ã€‚
	`
	question := "æˆ‘å‘¨æœ«æƒ³è¦å»è‹å·ç©ï¼Œä½ æœ‰ä»€ä¹ˆæ„è§ï¼Ÿ"

	fmt.Println(">", question)

	messages := []openai.ChatCompletionMessageParamUnion{
		openai.SystemMessage(prompt),
		openai.UserMessage(question),
	}

	isEnd := false

	for !isEnd {
		isEnd, messages = callGpt(client, messages, ctx)
		if len(messages) > 0 {
			fmt.Println(messages[len(messages)-1].(openai.ChatCompletionMessage).Content)
		}

	}

}

// TestStreaming æµ‹è¯•openai æµå¼è°ƒç”¨
func TestStreaming(t *testing.T) {
	client := openai.NewClient(
		option.WithBaseURL(baseUrl),
		option.WithAPIKey(apiKey), // defaults to os.LookupEnv("OPENAI_API_KEY")
	)

	chatStreaming := client.Chat.Completions.NewStreaming(context.TODO(), openai.ChatCompletionNewParams{
		Messages: openai.F([]openai.ChatCompletionMessageParamUnion{
			openai.UserMessage("å¸®æˆ‘å†™ä¸€ç¯‡æ–‡ç« ï¼Œé¢˜ç›®æ˜¯ã€Šå¦‚ä½•å†™ä¸€ç¯‡ä¼˜ç§€çš„æ–‡ç« ã€‹"),
		}),
		//Model: nexus.F("qwen-plus-0806"),
		Model: openai.F(model),
	})

	for chatStreaming.Next() {
		event := chatStreaming.Current()
		if len(event.Choices) > 0 {
			print(event.Choices[0].Delta.Content)
		}

	}

	println()

	if err := chatStreaming.Err(); err != nil {

		panic(err)

	}

}
