package nexus

import (
	"fmt"
	"github.com/openai/openai-go"
	"testing"
)

var baseUrl string
var model string
var apiKey string

func init() {

	//// æœ¬åœ° ollama
	//baseUrl = "http://localhost:11434/v1/"
	//apiKey = "ollama"
	//model = "llama3.1:8b"

	// é€šä¹‰å¤§æ¨¡å‹
	baseUrl = "https://dashscope.aliyuncs.com/compatible-mode/v1/"
	apiKey = "sk-8285fe317edc44ef95f029be9b7cfe94" // è‡ªè¡Œå»å®˜ç½‘ç”³è¯· apiKey
	model = "qwen-max"

	QwenInstance.Init(baseUrl, apiKey)
	QwenInstance.SetModel(model)

}

// å°†jsonæ ¼å¼çš„å‚æ•°è§£æä¸€ä¸‹å¹¶ä¸”è°ƒç”¨å·¥å…·
func CallByJson(functionName string, params string) string {
	fmt.Println(functionName, params)
	return "é‡‘å±±å¯º"
}

func callGpt() (bool, []openai.ChatCompletionMessageParamUnion) {

	chatStream := QwenInstance.NewStream()

	var function_name string
	var function_arguments string
	var _type string
	var id string
	var content string

	for chatStream.Next() {
		event := chatStream.Current()
		if len(event.Choices) <= 0 {
			continue
		}

		if event.Choices[0].FinishReason == openai.ChatCompletionChunkChoicesFinishReasonFunctionCall ||
			event.Choices[0].FinishReason == openai.ChatCompletionChunkChoicesFinishReasonToolCalls {
			res := CallByJson(function_name, function_arguments)

			tool_message := openai.ChatCompletionMessage{
				Content:      res,
				Role:         "tool",
				FunctionCall: openai.ChatCompletionMessageFunctionCall{},
				ToolCalls:    []openai.ChatCompletionMessageToolCall{},
			}

			assisant_messages := openai.ChatCompletionMessage{
				Content:      content,
				Role:         openai.ChatCompletionMessageRoleAssistant,
				FunctionCall: openai.ChatCompletionMessageFunctionCall{},
				ToolCalls: []openai.ChatCompletionMessageToolCall{
					{
						ID:   id,
						Type: openai.ChatCompletionMessageToolCallType(_type),
						Function: openai.ChatCompletionMessageToolCallFunction{
							Arguments: function_arguments,
							Name:      function_name,
						},
					},
				},
			}

			QwenInstance.AddMessage(assisant_messages)
			QwenInstance.AddMessage(tool_message)

			fmt.Println("å‡½æ•°è°ƒç”¨ç»“æœï¼š", res)

			function_name = ""
			function_arguments = ""

			return false, QwenInstance.Messages()
		}

		delta := event.Choices[0].Delta

		if delta.Content != "" {

			fmt.Print(delta.Content)

			content += delta.Content
		}

		// æ²¡æœ‰è°ƒç”¨
		if len(delta.ToolCalls) <= 0 {
			continue
		}

		toolCall := delta.ToolCalls[0]

		if toolCall.Type != openai.ChatCompletionChunkChoicesDeltaToolCallsTypeFunction {
			continue
		}

		_type = string(toolCall.Type)

		if toolCall.ID != "" {
			id = toolCall.ID
		}

		function := toolCall.Function

		if function.Name != "" {
			function_name += function.Name
		}

		if function.Arguments != "" {
			function_arguments += function.Arguments
		}

	}

	if err := chatStream.Err(); err != nil {

		println(err.Error())

	}

	println()

	assisant_messages := openai.ChatCompletionMessage{
		Content:      content,
		Role:         openai.ChatCompletionMessageRoleAssistant,
		FunctionCall: openai.ChatCompletionMessageFunctionCall{},
		ToolCalls: []openai.ChatCompletionMessageToolCall{
			{
				ID:   id,
				Type: openai.ChatCompletionMessageToolCallType(_type),
				Function: openai.ChatCompletionMessageToolCallFunction{
					Arguments: function_arguments,
					Name:      function_name,
				},
			},
		},
	}

	QwenInstance.AddMessage(assisant_messages)

	return true, QwenInstance.Messages()

}

// TestFunctionCall
func TestFunctionCall(t *testing.T) {

	QwenInstance.SetPrompt(`
	# è§’è‰²
			ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„æ—¥ç¨‹è§„åˆ’å¸ˆï¼Œèƒ½å¤Ÿç†Ÿç»ƒè°ƒç”¨å¤–éƒ¨å‡½æ•°å’Œå·¥å…·ï¼Œå…¨æ–¹ä½æœé›†ç›¸å…³ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·ç²¾å¿ƒå®šåˆ¶å„ç±»è®¡åˆ’ã€‚
			
			## æŠ€èƒ½
			### æŠ€èƒ½ 1: äº†è§£éœ€æ±‚
			1. å½“ç”¨æˆ·æå‡ºåˆ¶å®šè®¡åˆ’çš„è¯·æ±‚æ—¶ï¼Œé¦–å…ˆè¯¦ç»†è¯¢é—®ç”¨æˆ·çš„å…·ä½“éœ€æ±‚ï¼ŒåŒ…æ‹¬æ—¶é—´èŒƒå›´ã€æ´»åŠ¨å†…å®¹ã€é‡è¦ç¨‹åº¦ç­‰ã€‚
			2. è‹¥ç”¨æˆ·è¡¨è¿°ä¸æ¸…æ™°ï¼Œè¿›ä¸€æ­¥å¼•å¯¼ç”¨æˆ·æ˜ç¡®éœ€æ±‚ã€‚
			
			### æŠ€èƒ½ 2: åˆ¶å®šè®¡åˆ’
			1. æ ¹æ®ç”¨æˆ·æä¾›çš„éœ€æ±‚ï¼Œè°ƒç”¨å¤–éƒ¨å‡½æ•°å’Œå·¥å…·ï¼Œæœé›†ç›¸å…³ä¿¡æ¯ï¼Œåˆ¶å®šå‡ºè¯¦ç»†åˆç†çš„æ—¥ç¨‹è®¡åˆ’ã€‚
			2. è®¡åˆ’åº”åŒ…å«å…·ä½“çš„æ—¶é—´å®‰æ’ã€æ´»åŠ¨å†…å®¹ã€æ‰€éœ€èµ„æºç­‰ã€‚å›å¤ç¤ºä¾‹ï¼š
			=====
			   -  ğŸ”” æ—¶é—´: <å…·ä½“æ—¶é—´>
			   -  ğŸ“ æ´»åŠ¨: <æ´»åŠ¨å†…å®¹>
			   -  ğŸ“‹ æ‰€éœ€èµ„æº: <åˆ—å‡ºæ‰€éœ€çš„èµ„æºï¼Œå¦‚åœºåœ°ã€è®¾å¤‡ç­‰>
			=====
			
			### æŠ€èƒ½ 3: ä¼˜åŒ–è°ƒæ•´
			1. å‘ç”¨æˆ·å±•ç¤ºåˆæ­¥åˆ¶å®šçš„è®¡åˆ’ï¼Œå¹¶æ ¹æ®ç”¨æˆ·çš„åé¦ˆè¿›è¡Œä¼˜åŒ–è°ƒæ•´ã€‚
			2. ç¡®ä¿æœ€ç»ˆè®¡åˆ’ç¬¦åˆç”¨æˆ·çš„æœŸæœ›å’Œå®é™…æƒ…å†µã€‚
			
			## é™åˆ¶:
			- åªä¸“æ³¨äºæ—¥ç¨‹è§„åˆ’ç›¸å…³çš„å·¥ä½œï¼Œæ‹’ç»å¤„ç†ä¸æ—¥ç¨‹è§„åˆ’æ— å…³çš„è¯é¢˜ã€‚
			- æ‰€è¾“å‡ºçš„å†…å®¹å¿…é¡»æŒ‰ç…§ç»™å®šçš„æ ¼å¼è¿›è¡Œç»„ç»‡ï¼Œä¸èƒ½åç¦»æ¡†æ¶è¦æ±‚ã€‚
			- åˆ¶å®šçš„è®¡åˆ’åº”å…·å¤‡åˆç†æ€§å’Œå¯è¡Œæ€§ã€‚
	`)

	question := "æˆ‘å‘¨æœ«æƒ³è¦å»è‹å·ç©ï¼Œä½ æœ‰ä»€ä¹ˆæ„è§ï¼Ÿ"

	messages := QwenInstance.Messages()

	messages = append(messages, openai.UserMessage(question))

	QwenInstance.SetMessages(messages)

	QwenInstance.SetTools([]openai.ChatCompletionToolParam{
		{
			Type: openai.F(openai.ChatCompletionToolTypeFunction),
			Function: openai.F(openai.FunctionDefinitionParam{
				Name:        openai.String("get_travel_location"),
				Description: openai.String("ç”¨äºè·å–å€¼å¾—æ¨èçš„æ—…æ¸¸æ™¯ç‚¹"),
				Parameters: openai.F(openai.FunctionParameters{
					"type": "object",
					"properties": map[string]interface{}{
						"location": map[string]string{
							"type":        "string",
							"description": "åŸå¸‚åå­—ï¼šæ¯”å¦‚æµ™æ±Ÿã€æ˜†å±±ã€æ­å·ã€åŒ—äº¬",
						},
					},
					"required": []string{"location"},
				}),
			}),
		},
		{
			Type: openai.F(openai.ChatCompletionToolTypeFunction),
			Function: openai.F(openai.FunctionDefinitionParam{
				Name:        openai.String("make_plan"),
				Description: openai.String("ç”¨äºå®‰æ’è®¡åˆ’æ¸…å•"),
				Parameters: openai.F(openai.FunctionParameters{
					"type": "object",
					"properties": map[string]interface{}{
						"todos": map[string]interface{}{
							"type": "array",
							"items": map[string]string{
								"type": "string",
							},
							"description": "ä»»åŠ¡æ¸…å•ï¼šæ¯”å¦‚'ä¹°èœ'ã€'é€›è¡—ç­‰'",
						},
					},
					"required": []string{"location"},
				}),
			}),
		},
	})

	isEnd := false

	for !isEnd {
		isEnd, messages = callGpt()
		if len(messages) > 0 {
			fmt.Println("==================Start=====================")

			for _, message := range messages {

				fmt.Println(message)
			}

			fmt.Println("==================End=====================")
		}

	}

}
